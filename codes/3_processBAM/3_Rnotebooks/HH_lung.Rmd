---
title: "HH_lung"
output: html_document
---

## Environment   

### Notebook Global Setting        
```{r notebook_settings}
## knit options 
knitr::opts_chunk$set(eval = FALSE)

## controls whether to run 
INSTALL <- FALSE
WRITE <- FALSE

## paths 
DATA <- "/rds/general/user/ph323/ephemeral"
RESULT <- "~/MRes_project_1/docs/HH_ova/facet_input"
EXAMPLE <- "~/MRes_project_1/Codes/3_therapy_resp/example"
GATK <- "~/MRes_project_1/otherCodes/gatk-4.2.5.0/gatk" ## this is also a file exec
SNP_PILEUP <- "~/MRes_project_1/Codes/3_therapy_resp/pileup_exe/snp-pileup" ## this is a file exec
VCF_FILE <- "/MRes_project_1/Codes/3_therapy_resp/vcf_file"
```

### Library package 
```{r library_packages, eval=TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(magrittr)
library(httr)
library(Rsamtools)
library(facets)
library(ASCAT)
library(data.tree)
library(ABSOLUTE)
library(caroline)
library(DoAbsolute)
library(facetsSuite)
library(argparse)
library(ggplot2)
library(egg)
library(purrr)
library(tibble)
library(igvR)
library(readr)
library(readxl)
library(stringr)
library(survival)
library(nnet)
```

## Chapter 2: FACETS.    
**Required Files**:
1. snp-pileup exec with parameter specified below
2. vcf files.
3. output file name.
4. normal sample bam files.
5. tumour sample bam files.

### Check files 
```{r}
list.files(paste0(DATA, "/HH_lung/Alignment_lung"))
```

### SNP-Pileup 
This application will, given a VCF file containing SNP locations, output for each SNP the counts of the reference nucleotide, alternative nucleotide, errors, and deletions. These counts can then be used in facets.
Was developed on a linux machine and tested with htslib v1.3.1 conda install bioconda::htslib

**Installation**   
First, HTSlib must be installed on your system. To do that, download it from http://www.htslib.org/download/ and follow the “Building and installing” instructions on that page. If installed systemwide (in /usr/local/lib) using “make install” ensure that the libraries are available with the command “sudo ldconfig” (only needs to be run once).
This code can be compiled using `g++ -std=c++11 snp-pileup.cpp -lhts -o snp-pileup` when htslib is available systemwide, or `g++ -std=c++11 -I/path/htslib/include snp-pileup.cpp -L/path/htslib/lib -lhts -Wl,-rpath=/path/htslib/lib -o snp-pileup` when it is installed locally and path is the location where it is available.
```
#!/bin/bash

#PBS -l select=1:ncpus=1:mem=10gb
#PBS -l walltime=2:00:00
#PBS -N install_snp_pileup

## switch to facet directory snp folder 
cd ~/MRes_project_1/Codes/3_therapy_resp/pileup_exe/

## if snp-pileup does not exist, then 
if [ ! -f snp-pileup ]; then
    g++ -std=c++11 snp-pileup.cpp -lhts -o snp-pileup ## compile file 
else
    find . -type f -name 'snp-pileup' ## if exist, print snp-pileup
fi 
```

**Usage**
snp-pileup <vcf file> <output file> <sequence files...>
Usage of snp-pileup requires a VCF file and one (or multiple) sequence filescontaining DNA. The sequence files should be in the BAM format, and both the VCF and all sequence files must be sorted. A suitable option for VCF is one from NCBI. ftp://ftp.ncbi.nlm.nih.gov/snp/organisms/human_9606/VCF/00-common_all.vcf.gz     
Use a VCF file that is consistent with the genome build used for aligning the sequencing data. Available snp/genome build versions are in directories human_9606_b149_GRCh37p13, human_9606_b150_GRCh37p13, human_9606_b149_GRCh38p7, human_9606_b150_GRCh38p7.

#### VCF file    
Compare Bam file and VCF file Chromosome orders      
```
#!/bin/bash

#PBS -l select=1:ncpus=1:mem=100gb
#PBS -l walltime=2:00:00
#PBS -N get_order_files

## change to vcf directory 
cd ~/MRes_project_1/Codes/3_therapy_resp/vcf_file
if [ ! -f 00-common_all.vcf.gz ] && [ ! -f vcf_order.txt ]; then
    ## clear environment 
    rm -f ./* 
    ## download vcf file for hg38 from broad institute    
    wget https://ftp.ncbi.nlm.nih.gov/snp/organisms/human_9606/VCF/00-common_all.vcf.gz 
    ## extract chr list 
    bcftools query -f '%CHROM\n' 00-common_all.vcf.gz | uniq > vcf_order.txt
else
    find . -type f -name 'vcf_order.txt' ## if exist, print snp-pileup
fi

## change to example file directory 
cd ~/MRes_project_1/Codes/3_therapy_resp/example
## check the alignment of the bam files (normal-tumour paired) and vcf files 
samtools idxstats X991T_sorted_nodup.bam | cut -f 1 | uniq > X991T_order.txt
samtools idxstats X991N_sorted_nodup.bam | cut -f 1 | uniq > X991N_order.txt
samtools idxstats X970T_sorted_nodup.bam | cut -f 1 | uniq > X970T_order.txt
samtools idxstats X970N_sorted_nodup.bam | cut -f 1 | uniq > X970N_order.txt

ls -l
```

```{r}
## Check: Are the order of chromosomes same across all the tumour and normal samples for different patients? 
setwd("~/MRes_project_1/Codes/3_therapy_resp/example")
files <- list.files(pattern = "_order\\.txt$") ## list the ordering files 
order <- lapply(files, read.table) %>% as.data.frame()
colnames(order) <- gsub("_order.txt", "", files)
order <- order[1:194, ] ## remove the asterisk
ANSWER <- lapply(order, identical, order$X970N) %>% unlist ## proving that the chromosome order is unified across all samples 
print(paste("Are the order of chromosomes same across all the tumour and normal samples for different patients?", ANSWER))

## Check: Is VCF order same as other orders? 
vcf_order <- read.table("~/MRes_project_1/Codes/3_therapy_resp/vcf_file/vcf_order.txt") %>% unlist
cancer_order <- read.table("~/MRes_project_1/Codes/3_therapy_resp/lung_order.txt") %>% unlist
ANSWER <- identical(order$standard, vcf_order)
print(paste("Is VCF order same as other orders?", ANSWER))
print(vcf_order)

## order + vcf 
vcf_new_order <- order$X970N[c(1:22, 24:25)]
if(WRITE){
  write.table(vcf_new_order, file = "~/MRes_project_1/Codes/3_therapy_resp/vcf_file/vcf_new_order.txt", 
            row.names = FALSE, quote = FALSE)
}
```

Realign the vcf files according to the new order.

```
#!/bin/bash

#PBS -l select=1:ncpus=1:mem=100gb
#PBS -l walltime=2:00:00
#PBS -N resort_vcf_file

## reorder vcf file 
cd ~/MRes_project_1/Codes/3_therapy_resp/vcf_file/

if [ ! -f sorted_vcf_file.vcf.gz ] && [ ! -f sorted_vcf_file.vcf ]; then 
    gunzip 00-common_all.vcf.gz
    grep '^#' 00-common_all.vcf > header.vcf
    awk 'NR==FNR{a[$1]=NR; next} !/^#/ {print a[$1],$0}' vcf_new_order.txt 00-common_all.vcf | sort -k1,1n | cut -d' ' -f2- > sorted_body.vcf
    cat header.vcf sorted_body.vcf > sorted_vcf_file.vcf
    bgzip sorted_vcf_file.vcf 
else
    find . -type f -name 'sorted_vcf_file.vcf.gz' ## if exist, print snp-pileup
fi 
```

#### Bam Files 
Because FACETS requires normal tumour pair, therefore we will set a random sample “X991N” as control against the 21 single samples. In the FACETS analysis, we will specify that the pair is not matched. For SNP-pileup we will formulate two lists of bam file names for snp-pileup exec to call upon.   
```{r bam_files, eval=TRUE}
## extract the files that is not paired 
# Assuming you're working in the directory containing the files:
file_list <- list.files(path = "/rds/general/user/ph323/ephemeral/HH_lung/Alignment_lung", pattern = "_sorted_nodup.bam$")  
file_list %>% unique %>% length()

unpaired_tumour <- file_list %>% unique 
unpaired_normal <- rep("X991N_sorted_nodup.bam", length(unpaired_tumour))

## combine the files 
normal <- c(unpaired_normal, paired_normal) ## the first 21 samples will not be matched 
tumour <- c(unpaired_tumour, paired_tumour) 

## check if the paired bam files are matched up by randomly sample a few  
## for samples from 22 to 119, the sample_ids should be identical.   
## for samples from 1 to 21, the normal sample should all be X991N.    
set.seed(1234)
random <- sample(1:119, 12, replace = FALSE)
for(i in random){
  print(c(i, normal[i], tumour[i]))
}

## process 
if(WRITE){
  write.table(unpaired_tumour, "~/MRes_project_1/Codes/3_therapy_resp/lung_tumour_order.txt", 
              row.names = FALSE, quote = FALSE)
  write.table(unpaired_normal, "~/MRes_project_1/Codes/3_therapy_resp/lung_normal_order.txt", 
              row.names = FALSE, quote = FALSE)
  write.table(unique(sample_ids), "~/MRes_project_1/Codes/3_therapy_resp/sample_ids.txt", 
              row.names = FALSE, quote = FALSE)
}
```

#### pileup:       
The input VCF file should contain polymorphic SNPs, so that FACETS can infer changes in allelic configuration at genomic loci from changes in allele ratios. dbSNP is a good source for this. By default, snp-pileup also estimates the read depth in the input BAM files every 50th base.    
```{bash}
#!/bin/bash

#PBS -l select=1:ncpus=1:mem=100gb
#PBS -l walltime=24:00:00
#PBS -N snp_pileup

## first switch to result directory to check if this step has been done for all samples 
cd ~/MRes_project_1/docs/HH_lung/facets/facet_input/
file_count=$(find . -type f -name '*_ordered.csv.gz' | wc -l) ## count the number of processed files 
N=52 ## number of samples 

# Compare file count
if [ $file_count -lt $N ]; then 
    
    ## change directory to where the bam files were stored 
    cd /rds/general/user/ph323/ephemeral/HH_lung/Alignment_lung
    
    ## set dead parameters: 
    snp_pileup_path="/rds/general/user/ph323/home/MRes_project_1/Codes/3_therapy_resp/pileup_exe/snp-pileup"
    params="-g -q15 -Q20 -P100 -r25,0"
    vcf="/rds/general/user/ph323/home/MRes_project_1/docs/snp_pileup/sorted_vcf_file.vcf.gz"
    
    ## set live parameters: 
    normal_bams=($(cat /rds/general/user/ph323/home/MRes_project_1/Codes/3_therapy_resp/lung_normal_order.txt))
    tumour_bams=($(cat /rds/general/user/ph323/home/MRes_project_1/Codes/3_therapy_resp/lung_tumour_order.txt))

    # Loop over the BAM files
    for ((i=1; i<=$N; i++)); do
        ## Adjust index for zero-based array
        adjusted_index=$((i - 1))

        ## Extract normal and tumor bam file paths
        normal_bam="${normal_bams[$adjusted_index]}"
        tumor_bam="${tumour_bams[$adjusted_index]}"
        
        ## Construct output file path
        output_file_name=$(basename "${tumor_bam}" "_sorted_nodup.bam")
        output_file="~/MRes_project_1/docs/HH_lung/facets/facet_input/${output_file_name}.csv"

        ## Construct the command
        cmd="$snp_pileup_path $params $vcf $output_file $normal_bam $tumor_bam"
        
        # Run the command
        echo "Running: $cmd"
        eval $cmd
        
        echo "Finished piling ${output_file_name}"
    done
else 
    find . -type f -name '*_ordered.csv.gz' | wc -l
fi
```

#### reorder the pileup file and gunzip them for subsequent run-facets wrapper    
```{r gunzip_snp_pileup}
## reorder the snp-pileup outputs before executing facets 
for(cancer in sample_ids){
  ## output file: 
  setwd("~/MRes_project_1/docs/HH_ova/facets/facet_input")
  output <- paste0(cancer, "_ordered.csv")
  gzip_output <- paste0(cancer, "_ordered.csv.gz")
  
  if (!file.exists(output)) {
    ## reorder the snp_pileup files to 1, 2, 3... 22, X, Y format 
    temp <- read.csv(paste0("~/MRes_project_1/docs/HH_ova/facets/facet_input/", cancer, ".csv")) ## read in files 
    chrom_order <- c(as.character(1:22), "X", "Y")  ## set up the order 
    temp <- temp[order(match(temp$Chromosome, chrom_order), temp$Position), ] ## reorder 
    
    write.csv(temp, paste0("~/MRes_project_1/docs/HH_ova/facets/facet_input/", cancer, "_ordered.csv"), 
              quote = FALSE, col.names = TRUE, row.names = FALSE)  ## save the files 
  } else if (!file.exists(gzip_output)){
    temp <- read.csv(paste0("~/MRes_project_1/docs/HH_ova/facets/facet_input/", cancer, "_ordered.csv"))
    write.csv(temp, gzfile(paste0("~/MRes_project_1/docs/HH_ova/facets/facet_input/", cancer, "_ordered.csv.gz")), 
              row.names = FALSE)
  }
}
```

### run_facets_wrapper.R     
facetsSuite is an R package with functions to run FACETS—an allele-specific copy-number caller for paired tumor-normal DNA-sequencing data from genome-wide and targeted assays. facetSuite both wraps the code to execute the FACETS algorithm itself as well as performs post-hoc analyses on the resulting data. This package was developed by members of the Taylor lab and the Computational Sciences group within the Center for Molecular Oncology at Memorial Sloan Kettering Cancer Center.

This wrapper takes above SNP “pileup” as input and executes the FACETS algorithm. The ouputs are in the form of Rdata objects, TXT files, and PNGs of the samples overall copy-number profile. The wrapper allows for running FACETS in a two-pass mode, where first a “purity” run estimates the overall segmentation profile, sample purity and ploidy, and subsequently the dipLogR value from this run seeds a “high-sensitivity” run which may detect more focal events. To run in the two-pass mode, specify the input arguments prefixed by purity. The cval (–purity-cval and –cval) parameters tune the segmentation coarseness.      

```
#!/bin/bash

#PBS -l select=1:ncpus=1:mem=100gb
#PBS -l walltime=24:00:00
#PBS -N run_facet

# Set Job Home Directory
JOB_HOME=/rds/general/user/ph323/home/MRes_project_1/Codes/3_therapy_resp
cd $JOB_HOME

# Assuming sample_ids.txt is in the JOB_HOME directory
# Use full path if the file is somewhere else
SAMPLE_IDS_PATH="$JOB_HOME/sample_ids.txt"

if [ -f "$SAMPLE_IDS_PATH" ]; then
    mapfile -t cancer_list < "$SAMPLE_IDS_PATH"

    # Loop through each cancer type
    for cancer in "${cancer_list[@]}"; do
        counts_file="/rds/general/user/ph323/home/MRes_project_1/docs/HH_ova/facets/facet_input/${cancer}_ordered.csv.gz"
        directory="/rds/general/user/ph323/home/MRes_project_1/docs/HH_ova/facets/facet_output/${cancer}"
        mkdir -p "$directory" 

        $JOB_HOME/facets-suite/run-facets-wrapper.R \
            --counts-file "$counts_file" \
            --sample-id ${cancer} \
            --directory "$directory" \
            --everything \
            --genome 'hg38' \
            --cval 50 \
            --purity-cval 100 \
            --facets-lib-path "/rds/general/user/ph323/home/anaconda3/envs/Renv/lib/R/library"
        echo "Processed ${cancer}"
    done
else
    echo "Error: sample_ids.txt not found in $SAMPLE_IDS_PATH"
    exit 1
fi
```
The above command runs FACETS in the two-pass mode, first at cval 50, then at cval 25 based on the sample-specific baseline found at the higher cval. The full suite of analysis and QC is run with the –everything flag. If no output directory is specified, a directory named sample-id is created.       
\   

To understand the result we produce, we will first look at what kinds of files are produced by facet-suite wrapper. We'll use X991 as an example.      
```{r, eval=TRUE}
sample_ids <- unique(sample_ids)
```


#### Quality of our run      
```{r quality_control}
## make empty table 
quality_control <- read.table(paste0("~/MRes_project_1/docs/HH_ova/facets/facet_output/", 
                                     sample_ids[1], "/", sample_ids[1], ".qc.txt"), header = TRUE)
summary_table <- read.table(paste0("~/MRes_project_1/docs/HH_ova/facets/facet_output/", 
                             sample_ids[1], "/", sample_ids[1], ".txt"), header = TRUE, sep = "\t")     
arm_level <- read.table(paste0("~/MRes_project_1/docs/HH_ova/facets/facet_output/", 
                             sample_ids[1], "/", sample_ids[1], ".arm_level.txt"), header = TRUE, sep = "\t") 
gene_level <- read.table(paste0("~/MRes_project_1/docs/HH_ova/facets/facet_output/", 
                             sample_ids[1], "/", sample_ids[1], ".gene_level.txt"), header = TRUE, sep = "\t") 

## loop thorugh all the files 
for(i in 2:length(sample_ids)) {
  ## make file path 
  file_path_qc <- paste0("~/MRes_project_1/docs/HH_ova/facets/facet_output/", sample_ids[i], "/", sample_ids[i], ".qc.txt")
  file_path_s <- paste0("~/MRes_project_1/docs/HH_ova/facets/facet_output/", sample_ids[i], "/", sample_ids[i], ".txt")
  file_path_a <- paste0("~/MRes_project_1/docs/HH_ova/facets/facet_output/", sample_ids[i], "/", sample_ids[i], ".arm_level.txt")
  file_path_g <- paste0("~/MRes_project_1/docs/HH_ova/facets/facet_output/", sample_ids[i], "/", sample_ids[i], ".gene_level.txt")
  
  if(file.exists(file_path_qc)) {
    ## quality_control 
    temp_qc <- read.table(file_path_qc, header = TRUE)
    quality_control <- rbind(quality_control, temp_qc)
  }
  if(file.exists(file_path_s)) {
    ## summary_table
    temp_s <- read.table(file_path_s, header = TRUE, sep = "\t")
    summary_table <- rbind(summary_table, temp_s)
  }
  if(file.exists(file_path_a)) {
    ## arm level 
    temp_a <- read.table(file_path_a, header = TRUE, sep = "\t")
    arm_level <- rbind(arm_level, temp_a)
  }
  if(file.exists(file_path_g)) {
    ## gene level 
    temp_g <- read.table(file_path_g, header = TRUE, sep = "\t")
    gene_level <- rbind(gene_level, temp_g)
  }
}

summary_table$flags <- NULL

write.csv(quality_control, "~/MRes_project_1/docs/HH_ova/facets/quality_control/quality_control.csv", 
          row.names = FALSE, quote = FALSE)
write.table(summary_table, "~/MRes_project_1/docs/HH_ova/facets/quality_control/summary_table.txt", 
          row.names = FALSE, quote = FALSE)
write.csv(arm_level, "~/MRes_project_1/docs/HH_ova/facets/quality_control/arm_level.csv", 
          row.names = FALSE, quote = FALSE)
write.csv(gene_level, "~/MRes_project_1/docs/HH_ova/facets/quality_control/gene_level.csv", 
          row.names = FALSE, quote = FALSE)
```

###### Quality Control table:    
```{r, eval=TRUE}
quality_control <- read.csv("~/MRes_project_1/docs/HH_ova/facets/quality_control/quality_control.csv", header = TRUE)
summary(quality_control)
```

1. sample: The identifier for the sample analyzed.      
2. cval: cutoff value used in the FACETS analysis to determine significant copy number alterations.        
3. dipLogR_flag: A logical flag indicating whether any issues were detected with the dipLogR value.     
4. n_alternative_dipLogR: The number of alternative dipLogR values found. These are other log-ratio values at which a balanced copy number state is observed.       
5. wgd: Whole Genome Doubling, a boolean indicating whether the whole genome appears to have been duplicated.       
6. fga: Fraction of Genome Altered, the proportion of the genome that shows copy number alterations.       
7. n_dip_bal_segs: Number of segments with balanced copy number that are diploid.       
8. frac_dip_bal_segs: Fraction of segments with balanced copy number that are diploid.       
9. n_dip_imbal_segs: Number of segments with imbalanced copy number that are diploid.       
10. frac_dip_imbal_segs: Fraction of segments with imbalanced copy number that are diploid.       
11. n_amps: Number of amplifications detected.       
12. n_homdels: Number of homozygous deletions detected.       
13. frac_homdels: Fraction of the genome affected by homozygous deletions.       
14. n_homdels_clonal: Number of clonal homozygous deletions detected.       
15. frac_homdels_clonal: Fraction of the genome affected by clonal homozygous deletions.       
16. n_cn_states: Number of different copy number states identified across the genome.       
17. n_segs: Total number of segments identified in the copy number analysis.       
18. n_cnlr_clusters: Number of clusters identified when fitting the copy number log ratios.       
19. n_lcn_na: Number of segments where the local copy number could not be assessed.       
20. n_loh: Number of loss of heterozygosity events detected.       
21. frac_loh: Fraction of the genome affected by LOH.       
22. n_segs_subclonal: Number of segments identified as subclonal.       
23. frac_segs_subclonal: Fraction of the genome that is subclonal.       
24. n_segs_below_dipLogR: Number of segments with values below the baseline dipLogR, suggesting deletion.       
25. frac_below_dipLogR: Fraction of segments with values below the baseline dipLogR.       
26. n_segs_balanced_odd_tcn: Number of segments with an odd total copy number that are balanced.       
27. frac_balanced_odd_tcn: Fraction of segments with an odd total copy number that are balanced.       
28. n_segs_imbalanced_diploid_cn: Number of segments that are diploid yet imbalanced.       
29. frac_imbalanced_diploid_cn: Fraction of segments that are diploid yet imbalanced.       
30. n_segs_lcn_greater_mcn: Number of segments with a local copy number greater than the median copy number.       
31. frac_lcn_greater_mcn: Fraction of segments with a local copy number greater than the median copy number.       
32. n_snps: Total number of SNPs analyzed.       
33. n_het_snps: Number of heterozygous SNPs.       
34. frac_het_snps: Fraction of SNPs that are heterozygous.       
35. n_snps_with_300x_in_tumor: Number of SNPs with at least 300x coverage in the tumor.       
36. n_het_snps_with_300x_in_tumor: Number of heterozygous SNPs with at least 300x coverage in the tumor.       
37. n_het_snps_hom_in_tumor_1pct: Number of heterozygous SNPs homozygous in the tumor with a frequency of at least 1%.       
38. n_het_snps_hom_in_tumor_5pct: Number of heterozygous SNPs homozygous in the tumor with a frequency of at least 5%.       
39. frac_het_snps_hom_in_tumor_1pct: Fraction of heterozygous SNPs homozygous in the tumor with a frequency of at least 1%.       
40. frac_het_snps_hom_in_tumor_5pct: Fraction of heterozygous SNPs homozygous in the tumor with a frequency of at least 5%.       
41. mean_cnlr_residual: Mean residual from the copy number log ratio fits.       
42. sd_cnlr_residual: Standard deviation of the residuals from the copy number log ratio fits.       
43. n_segs_discordant_tcn: Number of segments with discordant total copy number.       
44. frac_discordant_tcn: Fraction of segments with discordant total copy number.       
45. n_segs_discordant_lcn: Number of segments with discordant local copy number.       
46. frac_discordant_lcn: Fraction of segments with discordant local copy number.       
47. n_segs_discordant_both: Number of segments with both discordant total and local copy numbers.       
48. frac_discordant_both: Fraction of segments with both discordant total and local copy numbers.       
49. n_segs_icn_cnlor_discordant: Number of segments with discordant integer copy number and copy number log ratio.       
50. frac_icn_cnlor_discordant: Fraction of segments with discordant integer copy number and copy number log ratio.       
51. mafr_median_all: Median minor allele frequency ratio across all segments.       
52. mafr_median_clonal: Median minor allele frequency ratio across clonal segments.       
53. mafr_n_gt_1: Number of segments with a minor allele frequency ratio greater than 1.       

###### Summary_table.    
```{r summary, eval=TRUE, fig.height=6, fig.width=8}
summary_table <- read.table("~/MRes_project_1/docs/HH_ova/facets/quality_control/summary_table.txt", 
                            header = TRUE)
hist(as.numeric(summary_table$purity), breaks = 15, xlim = c(0, 1), 
     ylim = c(0, 30), main = "purity", xlab = "score")
hist(as.numeric(summary_table$ploidy), xlim = c(1, 6), 
     ylim = c(0, 120), main = "ploidy", xlab = "score")
summary(summary_table)
```

###### Arm level      
```{r arm_level, eval=TRUE}
arm_level <- read.csv("~/MRes_project_1/docs/HH_ova/facets/quality_control/arm_level.csv", header = TRUE)
summary(arm_level)
```

###### Gene level      
```{r gene_level, eval=TRUE}
gene_level <- read.csv("~/MRes_project_1/docs/HH_ova/facets/quality_control/gene_level.csv", header = TRUE)
summary(gene_level)
```


#### Segmentation file      
To process the segmentation file output from facets which is stored in independent directories named after the sample processed. We will write a function with input sample id and segmentation file type to concatenate all segmentation files together into a big segmentation file.     
There are 4 kinds of segmentation file produced by FACETS-suite:    
1. hisens_diplogR.adjusted.seg       
2. hisens_diplogR.unadjusted.seg       
3. purity_diplogR.adjusted.seg       
4. purity_diplogR.unadjusted.seg        
Essentially the purity output is the first pass result (as detailed before facets-suite runs in a two pass mode). It estimates the **overall** segmentation profile, sample purity and ploidy. The resulting dipLogR (which is the inferred sample specific baseline corresponding to the diploid state) is then feeded into second run to generate a "high-sensitivity" run which may detect **more focal events**.      
What is dipLogR exactly?    
```
Well, to measure how many copies of a chromosome or a region of DNA a sample has, scientists use LogR (log ratio) which compares th amount of DNA in tumour sample to a normal sample. LogR of 0 means that tumour has same amount of DNA in that region as the normal sample (hence diploid). Positive LogR means extra copies and negative LogR means fewer copies. The "dip" in dipLogR stands for diploid, and dipLogR is the baseline LogR value that corresponds to this normal diploid state in the tumour sample. Because tumours can have overall more or fewer copies of DNA, the dipLogR helps set a baseline for what is considered "normal" within the tumor. If the tumor is mostly diploid, the dipLogR should be close to 0. In this case, the `diplogR.adjusted` segments means that the algorithm uses the dioLogR value to adjust the data. This adjustment identifies which DNA regions have gained or lost copies in the tumour cells. It accounts for situations when sample is impure (mixture of tumour and normal cells) or when tumour cells have an overall different number of DNA copies. Allowing for more accurate identificatin of changes due to cancer and removing random normal variations. 
```

```{r seg_function, eval=TRUE}
facet_process <- function(sample_ids, seg_file_type, facet_dir, seg_file_dir){
  ## sample_id from sample_ids 
  ## seg_file_type: _hisens_diplogR.adjusted.seg, _hisens_diplogR.unadjusted.seg, 
  ##                _purity_diplogR.adjusted.seg, _purity_diplogR.unadjusted.seg
  ## facet_directory: facet_cval_25 or facet_cval_50
  ## seg_file_dir: seg_cval_50, seg_cval_25
  
  ## build an empty dataframe 
  temp <- matrix(NA, nrow = 1, ncol = 6) %>% as.data.frame
  colnames(temp) <- c("ID", "chrom", "loc.start", "loc.end", "num.mark", "seg.mean")
  
  
  ## loop through each directory and get the dataframe 
  for(sample_id in sample_ids){
    ## set directory and switch to directory 
    directory <- file.path(paste0("/rds/general/user/ph323/home/MRes_project_1/docs/HH_ova/facets/", facet_dir,"/", sample_id))
    setwd(directory)
    
    ## import hisens_adj segmented file 
    segmented_file <- read.table(paste0(sample_id, seg_file_type), header = TRUE)
    temp <- rbind(temp, segmented_file)
  }
  ## remove the first NA row 
  temp <- temp[2:nrow(temp), ]

  ## print the result 
  print(gsub("_|\\.", " ", seg_file_type))
  print(summary(temp))
  
  ## write the file 
  output_dir <- file.path(paste0("/rds/general/user/ph323/home/MRes_project_1/docs/HH_ova/facets/", seg_file_dir))
  setwd(output_dir)
  write.table(temp, seg_file_type, quote = FALSE, row.names = FALSE, col.names = FALSE, sep = "\t")
  
  ## return the file 
  return(temp)
}
```

Now apply the function to produce the initial segmentation files from facets output.      
```{r segmentation_file_1}
## facet_directory: facet_output or facet_cval50
  ## seg_file_dir: seg_cval_50, seg_cval_25
  
hisens_adj <- facet_process(sample_ids, "_hisens_diplogR.adjusted.seg", "facet_cval_50", "seg_cval_50")
hisens_unadj <- facet_process(sample_ids, "_hisens_diplogR.unadjusted.seg", "facet_cval_50", "seg_cval_50")
purity_adj <- facet_process(sample_ids, "_purity_diplogR.adjusted.seg", "facet_cval_50", "seg_cval_50")
purity_unadj <- facet_process(sample_ids, "_purity_diplogR.unadjusted.seg", "facet_cval_50", "seg_cval_50")
```

To review the quality and coverage of our segmentation file, we will put the segmentation file into [IGV](https://github.com/igvteam/igv.js/blob/master/README.md) for inspect.    
```{java igv_view_seg}

```
![FACETS_cval50_IGV_hisens_adjusted](https://github.com/PollyHung/MRes_Project_1/blob/main/FACETS_cval50_IGV_hisens_adjusted.jpg)

Knowing that X1159 and X1876 have large chunk of missing coverages, we will remove these two samples before the next step analysis (ABSOLUTE and gistic) and recompile the segmentation file        
```{r segmentation_file_2}
## remove bad samples 
sample_ids_2 <- sample_ids[!sample_ids %in% c("X1159", "X1876")] %>% unique

## re-compile segmentation file 
hisens_adj <- facet_process(sample_ids_2, "_hisens_diplogR.adjusted.seg", "facet_cval_50", "seg_cval_50")
hisens_unadj <- facet_process(sample_ids_2, "_hisens_diplogR.unadjusted.seg", "facet_cval_50", "seg_cval_50")
purity_adj <- facet_process(sample_ids_2, "_purity_diplogR.adjusted.seg", "facet_cval_50", "seg_cval_50")
purity_unadj <- facet_process(sample_ids_2, "_purity_diplogR.unadjusted.seg", "facet_cval_50", "seg_cval_50")
```










